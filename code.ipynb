{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carvana Image Masking Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segmentation of images using U-Net Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "from sklearn.datasets import load_sample_image\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Dropout\n",
    "from keras.models import Model\n",
    "from os.path import join\n",
    "from os import listdir\n",
    "from keras.preprocessing import image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lib import augmentations as aug\n",
    "from lib import unet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = join(os.getcwd(), 'data')\n",
    "TRAIN_DIR = join(DATA_DIR, 'train')\n",
    "MASK_DIR = join(DATA_DIR, 'train_masks')\n",
    "TRAIN_IMAGE_LIST = listdir(TRAIN_DIR)\n",
    "MASK_IMAGE_LIST = listdir(MASK_DIR)\n",
    "ASPECT_RATIO = 1280 / 1918"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "train_images, test_images, train_masks, test_masks = train_test_split(TRAIN_IMAGE_LIST, MASK_IMAGE_LIST, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augumentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recreate_image(codebook, labels, w, h):\n",
    "    '''\n",
    "    Recreate the (compressed) image from the code book & labels\n",
    "    '''\n",
    "    d = codebook.shape[1]\n",
    "    image = np.zeros((w, h, d))\n",
    "    label_idx = 0\n",
    "    for i in range(w):\n",
    "        for j in range(h):\n",
    "            image[i][j] = codebook[labels[label_idx]]\n",
    "            label_idx += 1\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def color_quantize(img, target_colors):\n",
    "    '''\n",
    "    img: Source Image to perform Color Quantization.\n",
    "    target_colors: The number of bit of colors to quantize.\n",
    "    '''\n",
    "    img = img_to_array(img)\n",
    "    image_array = np.reshape(img, (img.shape[0] * img.shape[1], img.shape[2]))\n",
    "    image_array_sample = shuffle(image_array, random_state=0)[:1000]\n",
    "    kmeans = KMeans(n_clusters=target_colors, random_state=0).fit(image_array_sample)\n",
    "    labels = kmeans.predict(image_array)\n",
    "    return recreate_image(kmeans.cluster_centers_, labels, img.shape[0], img.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_generator_function(images, masks, batch_size, img_width = None, num_colors = 256):\n",
    "    \n",
    "    '''\n",
    "    images: Array of image names\n",
    "    masks: Array of mask names\n",
    "    batch_size: The number of images to be consider in one batch.\n",
    "    num_colors = target number of colors for kmeans algorithm. (Default = 256)\n",
    "    img_width: The width to which the original image is resized while maintaining aspect ratio. Does not resize if no parameters passed.\n",
    "    '''\n",
    "    \n",
    "    img_dim = [int(ASPECT_RATIO * img_width), img_width] if img_width is not None else None\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        random_indices = np.random.choice(len(images), batch_size)\n",
    "        \n",
    "        imgs = [img_to_array(color_quantize(load_img(join(TRAIN_DIR, images[index]), target_size = img_dim), num_colors)) / 255 for index in random_indices]\n",
    "        \n",
    "        masks = [img_to_array(load_img(join(MASK_DIR, masks[index]), target_size = img_dim)) / 255 for index in random_indices]\n",
    "        \n",
    "        yield np.array(imgs), np.array(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'uniform'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f16932d4df27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                                 \u001b[0mzoom_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                 \u001b[0mshear_chance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                                 shear_range=(-0.5, 0.5))\n\u001b[0m",
      "\u001b[0;32m/Users/alpombeo/ml_project_data/Carvana-Image-Masking-Challenge/lib/augmentations.py\u001b[0m in \u001b[0;36mrandom_augmentation\u001b[0;34m(img, mask, flip_chance, rotate_chance, rotate_limit, shift_chance, shift_limit_w, shift_limit_h, zoom_chance, zoom_range, shear_chance, shear_range, random_shear)\u001b[0m\n\u001b[1;32m    124\u001b[0m                                                                   \u001b[0mnew_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                                                                   \u001b[0mintensity_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshear_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshear_chance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                                                                  random_shear=random_shear)\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alpombeo/ml_project_data/Carvana-Image-Masking-Challenge/lib/augmentations.py\u001b[0m in \u001b[0;36m__random_shear__\u001b[0;34m(img, mask, intensity_range, u, random_shear)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mshear_rot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrandom_shear\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mroll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mroll\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mshear_rot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'uniform'"
     ]
    }
   ],
   "source": [
    "train_generator = image_generator_function(train_images, train_masks, 5, 500, 16)\n",
    "img_tmp, mask_tmp = next(train_generator)\n",
    "\n",
    "img, mask = aug.random_augmentation(img_tmp,\n",
    "                                mask_tmp,\n",
    "                                flip_chance=0,\n",
    "                                rotate_chance=0,\n",
    "                                rotate_limit=(-20,20),\n",
    "                                shift_chance=0, \n",
    "                                shift_limit_w=(-0.1, 0.1), \n",
    "                                shift_limit_h=(-0.1, 0.1),\n",
    "                                zoom_chance=0,\n",
    "                                zoom_range=(0.8, 1), \n",
    "                                shear_chance=1,\n",
    "                                shear_range=(-0.5, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "plot = 1\n",
    "for i in range(img.shape[0]):\n",
    "    plt.subplot(img.shape[0], 3, plot)\n",
    "    plt.imshow(img[i])\n",
    "    plot += 1\n",
    "    plt.subplot(img.shape[0], 3, plot)\n",
    "    plt.imshow(mask[i])\n",
    "    plot += 1\n",
    "    plt.subplot(img.shape[0], 3, plot)\n",
    "    plt.imshow(img[i])\n",
    "    plt.imshow(mask[i], alpha=0.5)\n",
    "    plot += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "model = unet.get_unet_model([128, 128, 3])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "nteract": {
   "version": "0.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
