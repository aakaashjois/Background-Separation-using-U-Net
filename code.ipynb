{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "from os import listdir, getcwd\n",
    "from os.path import join\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from lib import unet\n",
    "from lib import generator\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = join(getcwd(), 'data')\n",
    "TRAIN_DIR = join(DATA_DIR, 'train')\n",
    "MASK_DIR = join(DATA_DIR, 'train_masks')\n",
    "TRAIN_IMAGE_LIST = sorted(listdir(TRAIN_DIR))\n",
    "MASK_IMAGE_LIST = sorted(listdir(MASK_DIR))\n",
    "IMG_WIDTH = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "train_images, test_images, train_masks, test_masks = train_test_split(TRAIN_IMAGE_LIST, \n",
    "                                                                      MASK_IMAGE_LIST, \n",
    "                                                                      test_size=0.10000)\n",
    "train_images, validation_images, train_masks, validation_masks = train_test_split(train_images,\n",
    "                                                                                  train_masks,\n",
    "                                                                                  test_size=0.11111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentations - 320px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator = generator.image_generator(TRAIN_DIR, \n",
    "                                            MASK_DIR, \n",
    "                                            train_images, \n",
    "                                            train_masks, \n",
    "                                            batch_size = 5, \n",
    "                                            img_dim = [int((1280 / 1918) * IMG_WIDTH), IMG_WIDTH], \n",
    "                                            num_colors = 8)\n",
    "\n",
    "validation_generator = generator.image_generator(TRAIN_DIR, \n",
    "                                                 MASK_DIR, \n",
    "                                                 validation_images, \n",
    "                                                 validation_masks, \n",
    "                                                 batch_size = 5, \n",
    "                                                 img_dim = [int((1280 / 1918) * IMG_WIDTH), IMG_WIDTH], \n",
    "                                                 num_colors = 8)\n",
    "\n",
    "test_generator = generator.image_generator(TRAIN_DIR, \n",
    "                                           MASK_DIR, \n",
    "                                           test_images, \n",
    "                                           test_masks, \n",
    "                                           batch_size = 5, \n",
    "                                           img_dim = [int((1280 / 1918) * IMG_WIDTH), IMG_WIDTH], \n",
    "                                           num_colors = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = unet.get_unet_model([IMG_WIDTH, IMG_WIDTH, 3])\n",
    "\n",
    "model.compile(optimizer=Adam(1e-4), \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[unet.dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('best-fit-model-aug-320.hdf5',\n",
    "                             monitor='val_dice_coef',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit_generator(train_generator,\n",
    "                           steps_per_epoch = 814,\n",
    "                           epochs = 10,\n",
    "                           validation_data = validation_generator,\n",
    "                           validation_steps = 102,\n",
    "                           callbacks=[checkpoint])\n",
    "model.save('hist-aug-320.h5')\n",
    "pickle.dump(hist, open('hist-aug-320.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation - 640px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator.image_generator(TRAIN_DIR, \n",
    "                                            MASK_DIR, \n",
    "                                            train_images, \n",
    "                                            train_masks, \n",
    "                                            batch_size = 5, \n",
    "                                            img_dim = [int((1280 / 1918) * IMG_WIDTH), IMG_WIDTH], \n",
    "                                            num_colors = 8)\n",
    "\n",
    "validation_generator = generator.image_generator(TRAIN_DIR, \n",
    "                                                 MASK_DIR, \n",
    "                                                 validation_images, \n",
    "                                                 validation_masks, \n",
    "                                                 batch_size = 5, \n",
    "                                                 img_dim = [int((1280 / 1918) * IMG_WIDTH), IMG_WIDTH], \n",
    "                                                 num_colors = 8)\n",
    "\n",
    "test_generator = generator.image_generator(TRAIN_DIR, \n",
    "                                           MASK_DIR, \n",
    "                                           test_images, \n",
    "                                           test_masks, \n",
    "                                           batch_size = 5, \n",
    "                                           img_dim = [int((1280 / 1918) * IMG_WIDTH), IMG_WIDTH], \n",
    "                                           num_colors = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet.get_unet_model([IMG_WIDTH, IMG_WIDTH, 3])\n",
    "\n",
    "model.compile(optimizer=Adam(1e-4), \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[unet.dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('best-fit-model-aug-640.hdf5',\n",
    "                             monitor='val_dice_coef',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit_generator(train_generator,\n",
    "                           steps_per_epoch = 814,\n",
    "                           epochs = 10,\n",
    "                           validation_data = validation_generator,\n",
    "                           validation_steps = 102,\n",
    "                           callbacks=[checkpoint])\n",
    "model.save('hist-aug-640.h5')\n",
    "pickle.dump(hist, open('hist-aug-640.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Augmentation - 320px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator.image_generator_no_aug(TRAIN_DIR, \n",
    "                                            MASK_DIR, \n",
    "                                            train_images, \n",
    "                                            train_masks, \n",
    "                                            batch_size = 5, \n",
    "                                            img_dim = [int((1280 / 1918) * IMG_WIDTH), IMG_WIDTH], \n",
    "                                            num_colors = 8)\n",
    "\n",
    "validation_generator = generator.image_generator_no_aug(TRAIN_DIR, \n",
    "                                                 MASK_DIR, \n",
    "                                                 validation_images, \n",
    "                                                 validation_masks, \n",
    "                                                 batch_size = 5, \n",
    "                                                 img_dim = [int((1280 / 1918) * IMG_WIDTH), IMG_WIDTH], \n",
    "                                                 num_colors = 8)\n",
    "\n",
    "test_generator = generator.image_generator_no_aug(TRAIN_DIR, \n",
    "                                           MASK_DIR, \n",
    "                                           test_images, \n",
    "                                           test_masks, \n",
    "                                           batch_size = 5, \n",
    "                                           img_dim = [int((1280 / 1918) * IMG_WIDTH), IMG_WIDTH], \n",
    "                                           num_colors = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet.get_unet_model([IMG_WIDTH, IMG_WIDTH, 3])\n",
    "\n",
    "model.compile(optimizer=Adam(1e-4), \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[unet.dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('best-fit-model-no-aug-320.hdf5',\n",
    "                             monitor='val_dice_coef',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit_generator(train_generator,\n",
    "                           steps_per_epoch = 814,\n",
    "                           epochs = 10,\n",
    "                           validation_data = validation_generator,\n",
    "                           validation_steps = 102,\n",
    "                           callbacks=[checkpoint])\n",
    "model.save('hist-no-aug-320.h5')\n",
    "pickle.dump(hist, open('hist-no-aug-320.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Augmentation - 640px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator.image_generator_no_aug(TRAIN_DIR, \n",
    "                                            MASK_DIR, \n",
    "                                            train_images, \n",
    "                                            train_masks, \n",
    "                                            batch_size = 5, \n",
    "                                            img_dim = [int((1280 / 1918) * IMG_WIDTH), IMG_WIDTH], \n",
    "                                            num_colors = 8)\n",
    "\n",
    "validation_generator = generator.image_generator_no_aug(TRAIN_DIR, \n",
    "                                                 MASK_DIR, \n",
    "                                                 validation_images, \n",
    "                                                 validation_masks, \n",
    "                                                 batch_size = 5, \n",
    "                                                 img_dim = [int((1280 / 1918) * IMG_WIDTH), IMG_WIDTH], \n",
    "                                                 num_colors = 8)\n",
    "\n",
    "test_generator = generator.image_generator_no_aug(TRAIN_DIR, \n",
    "                                           MASK_DIR, \n",
    "                                           test_images, \n",
    "                                           test_masks, \n",
    "                                           batch_size = 5, \n",
    "                                           img_dim = [int((1280 / 1918) * IMG_WIDTH), IMG_WIDTH], \n",
    "                                           num_colors = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet.get_unet_model([IMG_WIDTH, IMG_WIDTH, 3])\n",
    "\n",
    "model.compile(optimizer=Adam(1e-4), \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[unet.dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('best-fit-model-no-aug-640.hdf5',\n",
    "                             monitor='val_dice_coef',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit_generator(train_generator,\n",
    "                           steps_per_epoch = 814,\n",
    "                           epochs = 10,\n",
    "                           validation_data = validation_generator,\n",
    "                           validation_steps = 102,\n",
    "                           callbacks=[checkpoint])\n",
    "model.save('hist-no-aug-640.h5')\n",
    "pickle.dump(hist, open('hist-no-aug-640.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "nteract": {
   "version": "0.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
